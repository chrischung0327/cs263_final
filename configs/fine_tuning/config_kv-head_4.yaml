lora:
    dropout: 0.05
    bias: none
    task_type: CAUSAL_LM
    target_modules: ["q_proj","k_proj","v_proj","o_proj","gate_proj","up_proj","down_proj"]
    r: 32
    alpha: 16

training:
    report_to: none
    learning_rate: 5e-5
    lr_scheduler_type: constant_with_warmup
    warmup_steps: 10
    num_train_epochs: 3 #5
    per_device_train_batch_size: 8
    gradient_accumulation_steps: 1
    output_dir: output_model
    overwrite_output_dir: True
    save_strategy: epoch
    save_total_limit: 1
    load_best_model_at_end: False
    logging_steps: 1
    seed: 0
    do_train: True
    do_eval: True
    do_predict: False
    eval_strategy: epoch
    gradient_checkpointing: True
    max_grad_norm: 0.3
    push_to_hub: False
    hub_private_repo: True

collator:
    response_template: "<|start_header_id|>assistant<|end_header_id|>"

trainer:
    max_seq_length: 500
    packing: false